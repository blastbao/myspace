---
title: "Locks实现:背后不为人知的故事"
description: "从事软件开发多年的你，真的了解locks背后的那些故事吗？锁是如何实现的，无锁真的是没有任何同步吗，为什么总是谈锁色变，锁究竟有哪些开销。本文将结合go sync.Mutex讨论下这些问题。"
date: 2021-04-17T11:32:36+08:00
categories: ["go设计实现"]
tags: ["lock","cmpxchg","cas","futex","sync.Mutex","go"]
toc: true
---

从事软件开发多年的你，真的理解locks背后的哪些故事吗？锁是如何实现的，无锁指的又是什么，无锁真的移除了任何同步操作吗？为什么大家总是谈锁色变，锁的开销真的有那么大吗，平时编码中又该注意些什么呢？本文将结合go sync.Mutex对这些问题进行讨论。

## 并发：我们关心什么

并发编程，开发人员应该对原子性、指令重排有深刻的认识。

### 原子性

大家都了解过数据库事务的原子性，类似地，程序中也经常有些操作也需要达到类似的效果——被某种类似事务的机制“保护”起来，要么全部执行要么全部不执行。通常我们将这样需要保护的代码段称为临界区。我们希望临界区内的代码要么全部执行要么全部不执行，达到这种原子性的效果。

其实不只是代码段，给一个int变量、struct的赋值，也需要考虑原子性，因为在不同的操作系统、处理器平台上，可能一个简单的int变量赋值需要涉及多条机器指令，而在多条指令执行期间，则可能发生各种事件，比如中断处理，比如被其他核的赋值指令写乱了同一变量的数据，都有可能。

这类原子性问题，需要应用程序级别的“高级锁”来做同步保证，如go sync.Mutex。

### 指令重排

指令重排的根源在于CPU的设计，古老的CPU只有一条取指、译码、执行、访存、写回的电路。联想下假如一个单线程程序执行阻塞网络IO的时候会发生什么，整个程序全阻塞在这里干不了其他的。CPU也存在类似问题，假如一条指令执行过程中因为数据没ready的问题不能执行，那CPU会stall，后续的指令都无法执行。

所以CPU为了提高指令吞吐，增加了多条流水线设计，可以同时执行多条指令的取指、译码、执行、访存、写回阶段，当然这其中有些指令是有数据依赖的，现代处理器支持寄存器重命名、指令乱序执行、重排序缓冲重排等功能，都是保证CPU执行效率的常用手段。

指令在CPU乱序执行，在某些并发场景下，可能会带来一些微妙的问题。比如：

```c
type num struct {
    a int
    b int
}

n := &num{}
go func() { n.a = 1; n.b = 2; }() // g1
go func() { n.a = 2; n.b = 1; }() // g2
```

你们说最终n.a，n.b的结果是多少呢？不确定的，虽然go现在只支持64位系统，现在处理器基本也都有64位mov指令，对a、b单独赋值都是原子的，但是对n整体的赋值不是。由于没有对n做保护，g1、g2中的赋值指令也没有什么数据一来，到时候乱序执行，g1 g2执行完成后，<n.a,n.b>的可能结果是：<1, 2> <1, 1> <2,1> <2,2>，这几种都有可能。

这就是指令重排造成的影响，如果我们在出现了指令重排的情况下，去做一些关键的判断逻辑，可能就会带来严重的bug。

这里重新回顾了下原子性、指令重排的含义，以及对程序正确习惯可能带来的影响，下面我们将尝试进一步考虑如何解决这些问题。

## 内存屏障：阻止指令重排

首先，我们看如何解决指令重排序问题，解铃还须系铃人，CPU流水线带来的问题，还需要CPU自己提供解决方案。CPU如何阻止指令重排序呢？

内存屏障，可以用来阻止屏障前后的指令重排序，保证屏障后的指令不会出现在屏障前执行，保证屏障前的指令不会在屏障后执行。相当于屏障之前和之后确立了happens-before关系，保证了屏障之前的操作对屏障之后的操作都是可见的。

CPU中通常提供了如下几条指令，用以建立内存屏障：

- lock：指令前缀，修饰指令保证指令执行时的排他性、原子性和完全内存屏障
- lock cmpxchg：cmpxchg比较并交换，配合lock前缀实现CAS
- mfence：完全内存屏障（load+store）
- lfence：读内存屏障（load）
- sfence：写内存屏障（store）

一些库函数或者编程语言提供的标准库，可以选择上述某汇编指令来实现内存屏障，或者实现可靠的CAS，并基于此进一步实现各种高级锁，如sync.Mutex。

## 内存屏障：到底是什么

写并发程序，Happens-Before关系经常挂嘴边，Happens-Before关系是很容易理解的，因为它是一个编程语言的内存模型锁明确定义的。如go中包级别变量的初始化操作与包内`func init()`之间存在Happens-Before关系，一个锁的Unlock和下次的Lock之间也存在HB关系，chan的send、recv之间也存在HB关系……

我们想要理解的是Happens-Before定义好之后，是如何实现的？当然是借助内存屏障了。那我们来看内存屏障怎么实现的，然后说是处理器提供的几条指令，那我想再问下这几条指令干了啥，为什么这几条指令就可以实现内存屏障。

计算机中包含了太多分层的设计思想，硬件对大多数软件开发人员来说是个黑盒，似乎管好分内的事，永远将它当做一个黑盒就好了。Well，处理器到底怎么实现内存屏障的还是比较吸引我，一句空洞的“栅栏”的比喻看似很形象但是打发不了我。我们就来看看硬件层面是怎么实现的。

如果不懂硬件设计、工作原理，只站在软件角度，是很难搞明白的，这个是很现实的问题，尽管了解了之后会发现很简单，但是经历这个阶段确实是需要很多时间来思考的。

### 内存屏障类型

- 全内存屏障（mfence）：barrier之前的load/store操作均比之后的先完成，且前后的指令不能共同参与指令重排序；
- 读屏障（lfence）：barrier之前的load比之后的load先完成；
- 写屏障（sfence）：barrier之前的store比之后的store先完成；

不同的处理器，均提供了自己的屏障指令，但是这些指令不管有什么异同，最终都与硬件设计相关，所以来看下现代处理器的一个大致设计。

### 处理器架构

下面是一个用来解释内存屏障的精简的处理器架构示意图，大约包含如下几部分。

<div style="width:100%;text-align:center;">
	<img alt="cpu" class="myimg" src="/blog/assets/locks/cpu.png"/>
</div>
- 多个CPU或CPU Core之间通过总线连接；
- CPU通过总线与主存（memory）连接；
- 每个CPU都有自己的本次cache，通过cache一致性协议（如MESI/MESIF）与其他CPU Core维护一个一致的数据视图；

下面结合上图，我们介绍下一此数据更新操作涉及的过程。

### 引入store buffer

CPU对cacheline的修改，若直接落cache，一致性协议会引入不小的开销，CPU会stall执行的指令。为了提高指令吞吐，这里引入了store buffer。

数据更新不直接写cacheline而是先写到store buffer，后面需要时再落cache并通知其他cache失效，这样CPU就可以减少stall继续执行指令。

<div style="width:100%;text-align:center;">
	<img alt="cpu2" class="myimg" src="/blog/assets/locks/cpu2.png"/>
</div>


### 引入invalidate queue

CPU cache更新cacheline后，通知其他CPU更新cache，需通过cache一致性协议，如MESI消息invalidate。

正常来说，收到此通知的CPU应从cache中将对应cacheline标记为无效，但是如果立即执行这个动作的话，CPU会频繁被阻断执行，所以CPU中引入了invalidate queue，收到invalidate通知后缓存起来并立即回复ACK，但延迟处理。

### 必要性及引入的问题

这么设计的必要性：

- 减少CPU更新本地cacheline、响应一致性协议invalidate通知导致的CPU stall问题，提高CPU利用率。
- 另外storebuffer、invalidate queue能支持在队列中排队，使我们有了指令重排的契机。

这么设计引入的问题：

- store buffer：本地cache更新不能立即被其他CPU或者CPU core观测到了，写操作对外不可见；
- invalidate queue：本地cache没有立即更新数据，上层应用看不到其他CPU更新的数据；

- cache一致性协议：它就是用来解决多个CPU共享一致性视图而设计的，但它只是一个协议，具体不同硬件设计的时候，某些屏障指令实现的时候要通过这里的cache一致性协议来保证多CPU、多核数据视图的一致性；

### 处理器执行操作变化

**如果没有store buffer、invalidate queue，MESI和cache如何工作？**

- 当包含变量a的cacheline，其被CPU 0和CPU 1共享，当CPU 0更新该cacheline之后，会发送invalidate给CPU 1，CPU 1随即把对应的cacheline标记为invalidate；
- 当CPU 1下次读取变量a的cacheline时，发现标记为了无效，此时发出read请求，CPU 0观测到自己这边对应的cacheline是modified状态，cacheline是最新的，此时会将对应cacheline数据发送给CPU 1，这样CPU 1就观测到了最新的数据；
- CPU 0中cacheline何时写回主存？可能是被淘汰的时候，也可能是别人read的时候，这个我们先不关心。

**如果引入了store buffer、invalidate queue之后，又该如何工作呢？**

- 必须要有办法，将该store buffer中的更新，通知到其他CPU，这就是write barrier干的事情。它就是暂停CPU 0执行，并将CPU 0把store buffer中记录的一些更新应用到cache中，此时会触发cache一致性协议MESI通知CPU 1 cacheline invalidate；
- 必须要有办法，将CPU 1中invalidate queue记录下来的invalidate对应的cacheline及时清理掉，这就是read barrier干的事情。它就是暂停CPU 1执行，将其invalidate queue中的每个invalidate请求对应的cacheline全部标记为无效，下次读取时从内存或者CPU 0读取最新数据；

### 处理器屏障指令

总结一下：

- 这里的读写屏障要依赖处理器提供的屏障指令
- 在屏障指令之上，内核可以按需选择，如Linux在x86平台选择用 `lock; addl`来实现读写屏障 smp_mb/smp_rmb/smp_wmb，x86其实也提供了mfence、lfence、sfence。至于Linux为什么这么选择，应该是跟x86实现有关系，一条指令`lock;addl`同时实现全屏障/读屏障/写屏障足矣。
- 其他编程语言内存模型，通常会定义一些Happens-Before关系，这里面就隐含了各种屏障的应用。基于屏障实现的各种同步原语如mutex、semaphore等就比较常见了。

### gc屏障 isn't 内存屏障

注意：有些人还把GC Barrier和Memory Barrier搞混了，碰到不止一个同学了：

- GC Barrier，是编译器插入的一些代码片段，用来跟踪mutator对heap做的修改；
- Memory Barrier，则就是本文这里讨论的内容，是处理器提供的一种低级的并发同步操作；

ps：真不知道怎么学的。

## Lock prefix VS Locks

CAS，一般都是基于处理器指令 `lock cmpxchg`来实现的，这里一定要搞明白，这里虽然指令修饰前缀的字面含义也是lock，翻译过来也是锁，但这并非我们通俗意义上的锁。

我们平时说的轻量级锁、重量级锁，比如spinlock、futex等，或者sync.Mutex, sync.RWMutex，这些锁都是“高级锁”，用“高级锁”是为了和处理器级别的lock修饰控制指令执行的排他性区分开。

lock指令前缀影响的只是单条指令，但是在lock+cmpxchg基础上可以实现更友好、实用的cas操作。如golang中的atomic.CompareAndSwap(...)。

不妨来看一下golang中CAS操作实现：

```asm
# filename: atomic_amd64.go
//go:noescape
func Cas64(ptr *uint64, old, new uint64) bool

# filename: atomic/doc.go
func CompareAndSwapInt64(ptr *uint64, old, new uint64) bool

# filename: atomic_amd64.s
// bool	·Cas64(uint64 *val, uint64 old, uint64 new)
// Atomically:
//	if(*val == *old){
//		*val = new;
//		return 1;
//	} else {
//		return 0;
//	}
TEXT ·Cas64(SB), NOSPLIT, $0-25
	MOVQ	ptr+0(FP), BX
	MOVQ	old+8(FP), AX
	MOVQ	new+16(FP), CX
	LOCK                                      # LOCK CMPXCHGQ, 排他性比较并交换
	CMPXCHGQ	CX, 0(BX)             
	SETEQ	ret+24(FP)
	RET

TEXT ·CompareAndSwapInt64(SB),NOSPLIT,$0
	JMP	runtime∕internal∕atomic·Cas64(SB)     # 调用的是上面的Cas64

```

可以看到，它就是用`lock cmpxchg`来实现的，常用的atomic.CompareAndSwap也差不多了多少，还是调用的Cas64。

然后我们再来看几个atomic包下的操作，来强化下对lock指令前缀的理解：

```asm
TEXT ·AddInt64(SB),NOSPLIT,$0
	JMP	runtime∕internal∕atomic·Xadd64(SB)
	
// uint64 Xadd64(uint64 volatile *val, int64 delta)
// Atomically:
//	*val += delta;
//	return *val;
TEXT ·Xadd64(SB), NOSPLIT, $0-24
	MOVQ	ptr+0(FP), BX
	MOVQ	delta+8(FP), AX
	MOVQ	AX, CX
	LOCK                              # LOCK XADDQ，排他性的add操作
	XADDQ	AX, 0(BX)
	ADDQ	CX, AX
	MOVQ	AX, ret+16(FP)
	RET
```

通常我们自己要应用cas的话，比如实现一个metrics gauge，可能会这么写：

```go
// Gauge 时刻量
type Gauge struct {
    v uint64
}

// IncrBy 时刻量+v
func (g *gauge) IncrBy(v float64) {
	for {
		oldBits := atomic.LoadUint64(&g.valBits)
		fv := math.Float64frombits(oldBits) + v
		newBits := math.Float64bits(fv)
		if atomic.CompareAndSwapUint64(&g.valBits, oldBits, newBits) {
			atomic.StoreUint32(&g.dirty, 1)
			return
		}
	}
}

...
```

先读取原始值，计算，然后准备写回，写回的时候用了CAS，一次CAS操作不一定成功，因为可能其他协程也在尝试更新，所以我们这里要结合一个循环（自旋，spin）来保证重试成功。基于CAS的无锁操作一般都是这么实现的。

### Locks VS Lock-free

这里读者也应该意识到了，前面CAS也是基于底层处理器的lock cmpxchg实现的，所以并不是说CAS操作就没有任何的同步措施。

有些lockfree的数据结构+算法，也是基于CAS实现的，也并不是就真的没有任何同步措施。只是没有用那些通俗意义上的“锁”（这种一般认为就是消除了锁竞争了）。

CAS和通俗意义的锁，相比之下，它的临界区非常小（单条指令），且不存在“锁”那样导致进程、线程、协程的挂起、恢复操作，没有上下文切换所引入的开销、调度延迟，所以开销更小一点。

## 实现一个锁

理解了CPU lock+cmpxchg的作用以及应用之后，就可以在此基础上实现一个简单的锁。

### 实现一个简单的spinlock

```go
type SpinLock struct{
    v int64
}

func (s *SpinLock) Lock() bool {
    for {
        if atomic.CompareAndSwap(&s.v, 0, 1) {
            return true
        }
    }
}

func (s *SpinLock) UnLock() {
    for {
        if atomic.CompareAndSwap(&s.v, 1, 0) {
            return
        }
    }
}
```

现在就可以拿这个锁去当做一个简单的锁去用了，但是，这种忙轮询的方式对CPU是一个比较严重的浪费，可以考虑一下如果长时间持有不了锁，是不是可以让出CPU给其他协程执行呢？可以，为了利用好CPU干有价值的事情，就应该让出去。

### 剥夺CPU：进/线/协程

现在我们想把不干活的可调度实体挂起，这里的可调度实体可能是进程、线程，也可能是协程。进程挂起可不是我们想要的，挂起、恢复太重了，线程在Linux下是轻量级进程实现的，挂起、恢复开销比进程小，但是仍然很大（一般要重量级锁会用到futex）。

<img alt="context switch cost" class="myimg" src="https://www.hitzhangjie.pro/libmill-book/assets/image%20%2815%29.png"/>

上图是一个上下文切换开销测评对比，感兴趣的话可以阅读[libmill-book](https://www.hitzhangjie.pro/libmill-book/basics/context-switching-cost.html)来了解。

一般的锁实现，拿不到锁最后都要将当前调用实体给挂起，比如把进程、线程挂起，等后续锁被释放可以用来唤起等待队列中的某个进程、线程，再恢复调度执行。

go语言中会怎么做呢？会使用futex做同样的处理吗？go好不容易实现了更轻量级的协程、协程切换、协程调度，肯定不会在“锁”这种地方妥协给futex让线程被挂起啊。

而且不使用futex是很自然的事情，因为go协程调度依赖的是go runtime，而非操作系统。虽然我们也会说用了sync.Mutex之后协程会阻塞，但是这里的阻塞只是M没有执行当前协程而已，并不是说之前执行的线程被阻塞了，和之前提及的线程因为futex阻塞完全不同。

这样，就可以实现一个非常轻量级的锁。

## sync.Mutex

终于来到了go语言相关的设计实现，go中sync.Mutex的设计有很多设计方面的考虑。

### 加锁过程

see https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L72

### fastpath

首先，会执行fastpath，会尝试CAS加锁一次，如果没有很多锁竞争，大概率会成功返回。

如果fastpath加锁失败了，则继续执行slowpath。

```go
// Lock locks m.
// If the lock is already in use, the calling goroutine
// blocks until the mutex is available.
func (m *Mutex) Lock() {
	// Fast path: grab unlocked mutex.
	if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) {
		if race.Enabled {
			race.Acquire(unsafe.Pointer(m))
		}
		return
	}
	// Slow path (outlined so that the fast path can be inlined)
	m.lockSlow()
}
```

### slowpath

这部分就有很多优化措施了，感兴趣的可以阅读这里的源码，我们先尝试总结下。



see https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L84

```go
const (
    ...
	// Mutex fairness.
	//
	// Mutex can be in 2 modes of operations: normal and starvation.
	// In normal mode waiters are queued in FIFO order, but a woken up waiter
	// does not own the mutex and competes with new arriving goroutines over
	// the ownership. New arriving goroutines have an advantage -- they are
	// already running on CPU and there can be lots of them, so a woken up
	// waiter has good chances of losing. In such case it is queued at front
	// of the wait queue. If a waiter fails to acquire the mutex for more than 1ms,
	// it switches mutex to the starvation mode.
	//
	// In starvation mode ownership of the mutex is directly handed off from
	// the unlocking goroutine to the waiter at the front of the queue.
	// New arriving goroutines don't try to acquire the mutex even if it appears
	// to be unlocked, and don't try to spin. Instead they queue themselves at
	// the tail of the wait queue.
	//
	// If a waiter receives ownership of the mutex and sees that either
	// (1) it is the last waiter in the queue, or (2) it waited for less than 1 ms,
	// it switches mutex back to normal operation mode.
	//
	// Normal mode has considerably better performance as a goroutine can acquire
	// a mutex several times in a row even if there are blocked waiters.
	// Starvation mode is important to prevent pathological cases of tail latency.
    ...
)

func (m *Mutex) lockSlow() {
	var waitStartTime int64
	starving := false
	awoke := false
	iter := 0
	old := m.state
	for {
		// Don't spin in starvation mode, ownership is handed off to waiters
		// so we won't be able to acquire the mutex anyway.
		if old&(mutexLocked|mutexStarving) == mutexLocked && runtime_canSpin(iter) {
			// Active spinning makes sense.
			// Try to set mutexWoken flag to inform Unlock
			// to not wake other blocked goroutines.
			if !awoke && old&mutexWoken == 0 && old>>mutexWaiterShift != 0 &&
				atomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) {
				awoke = true
			}
			runtime_doSpin()
			iter++
			old = m.state
			continue
		}
		new := old
		// Don't try to acquire starving mutex, new arriving goroutines must queue.
		if old&mutexStarving == 0 {
			new |= mutexLocked
		}
		if old&(mutexLocked|mutexStarving) != 0 {
			new += 1 << mutexWaiterShift
		}
		// The current goroutine switches mutex to starvation mode.
		// But if the mutex is currently unlocked, don't do the switch.
		// Unlock expects that starving mutex has waiters, which will not
		// be true in this case.
		if starving && old&mutexLocked != 0 {
			new |= mutexStarving
		}
		if awoke {
			// The goroutine has been woken from sleep,
			// so we need to reset the flag in either case.
			if new&mutexWoken == 0 {
				throw("sync: inconsistent mutex state")
			}
			new &^= mutexWoken
		}
		if atomic.CompareAndSwapInt32(&m.state, old, new) {
			if old&(mutexLocked|mutexStarving) == 0 {
				break // locked the mutex with CAS
			}
			// If we were already waiting before, queue at the front of the queue.
			queueLifo := waitStartTime != 0
			if waitStartTime == 0 {
				waitStartTime = runtime_nanotime()
			}
			runtime_SemacquireMutex(&m.sema, queueLifo, 1)
			starving = starving || runtime_nanotime()-waitStartTime > starvationThresholdNs
			old = m.state
			if old&mutexStarving != 0 {
				// If this goroutine was woken and mutex is in starvation mode,
				// ownership was handed off to us but mutex is in somewhat
				// inconsistent state: mutexLocked is not set and we are still
				// accounted as waiter. Fix that.
				if old&(mutexLocked|mutexWoken) != 0 || old>>mutexWaiterShift == 0 {
					throw("sync: inconsistent mutex state")
				}
				delta := int32(mutexLocked - 1<<mutexWaiterShift)
				if !starving || old>>mutexWaiterShift == 1 {
					// Exit starvation mode.
					// Critical to do it here and consider wait time.
					// Starvation mode is so inefficient, that two goroutines
					// can go lock-step infinitely once they switch mutex
					// to starvation mode.
					delta -= mutexStarving
				}
				atomic.AddInt32(&m.state, delta)
				break
			}
			awoke = true
			iter = 0
		} else {
			old = m.state
		}
	}

	if race.Enabled {
		race.Acquire(unsafe.Pointer(m))
	}
}
```



Mutex有两种工作模式：normal mode 和 starvation mode，两种模式有不同的影响。

- normal mode

  该模式下，waiters（goroutines）会按照加锁申请进入一个FIFO的队列，一个被唤醒的waiter不一定能够立即持有锁，它要和所有新的发起加锁请求的goroutines竞争。新到达的goroutines通常有一个优势——它们已经在CPU上运行了，并且有很多，所以一个刚被唤醒的waiter大概率会竞争锁失败。

  这种情况下，这个失败的waiter会被加入到这个FIFO队列的对首，如果一个waiter竞争锁超过1ms还没有成功，就会将mutex从normal mode切换为startvation mode。

- starvation mode

  该模式下，当一个goroutine释放锁时，锁的拥有者立即从该goroutine转交给对首的waiter。新到达的goroutines不会尝试获得锁，尽管它能观察到锁好像被释放掉了。这种模式下，新到达的goroutines会追加到FIFO的队列的末尾。

当一个waiter收到一个mutex的拥有者权限时，它会检查，如果：1）它是这个锁竞争等待队列中的最后一个waiter；或者 2）它的加锁等待时间小于1ms，此时将把mutex从starvation mode切换为normal mode。

## 总结

本文介绍了并发中重要的原子性、指令重排问题，以及带来的安全编码风险，然后介绍了处理器提供的一些屏障指令，以及从硬件角度介绍了屏障的工作原理，然后介绍了CAS及其使用，引出了进一步的锁、无锁、CAS的异同点，然后我们简单提了下futex重量级锁导致的进程线程挂起、恢复开销大家，最后引出了go sync.Mutex的设计实现及一系列针对协程调度延迟的优化。

希望本文对加深大家对锁的认识有帮助！

## 参考内容

1. Memory Barriers: a Hardware View for Software Hackers,http://www.puppetmastertrading.com/images/hwViewForSwHackers.pdf

2. how cpu lock cmpxchg works: http://heather.cs.ucdavis.edu/~matloff/50/PLN/lock.pdf
3. don't mix high-level locks with low-level CPU feature that happened to be renamed LOCK,https://stackoverflow.com/a/27856649/3817040
4. cpu-memory, https://akkadia.org/drepper/cpumemory.pdf

5. src/runtime/internal/atomic/atomic_386.s, https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/internal/atomic/atomic_386.s#L23
6. sync.Mutex, https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L81:4
7. Let's talk locks, Kavya Joshi, https://www.youtube.com/watch?v=tjpncm3xTTc